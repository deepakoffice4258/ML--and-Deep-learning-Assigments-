{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1cb861",
   "metadata": {},
   "source": [
    "# Describe the structure of an artificial neuron. How is it similar to a biological neuron? What are its main components?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e9137",
   "metadata": {},
   "source": [
    "an action potential is either triggered or not — biological synapses either carry a signal or they don't. ... The timing of the signals is synchronous, where artificial neurons in the same layer receive their input signals and then send their output signals all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c677b1",
   "metadata": {},
   "source": [
    "# What are the different types of activation functions popularly used? Explain each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15150c72",
   "metadata": {},
   "source": [
    "Binary Step Function.:-Binary step function is a threshold-based activation function which means after a certain threshold neuron is activated and below the said threshold neuron is deactivated. In the above graph, the threshold is zero\n",
    "Sigmoid/Logistic Activation Function:-The sigmoid activation function, also called the logistic function, is traditionally a very popular activation function for neural networks. The input to the function is transformed into a value between 0.0 and 1.0. ... The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.\n",
    "ReLU Activation Function:-The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. ... The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6a2ff",
   "metadata": {},
   "source": [
    "# Explain, in details, Rosenblatt’s perceptron model. How can a set of data be classified using a simple perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af2eae6",
   "metadata": {},
   "source": [
    "Rosenblatt perceptron is a binary single neuron model. The inputs integration is implemented through the addition of the weighted inputs that have fixed weights obtained during the training stage. If the result of this addition is larger than a given threshold θ the neuron fires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faeb5e7",
   "metadata": {},
   "source": [
    "# Explain the basic structure of a multi-layer perceptron. Explain how it can solve the XOR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09358e",
   "metadata": {},
   "source": [
    "It is the problem of using a neural network to predict the outputs of XOR logic gates given two binary inputs. ... An XOR function should return a true value if the two inputs are not equal and a false value if they are equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475cca9e",
   "metadata": {},
   "source": [
    "# What is artificial neural network (ANN)? Explain some of the salient highlights in the different architectural options for ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ebb02d",
   "metadata": {},
   "source": [
    "ANNs consist of artificial neurons. Each neuron in the middle layer takes the sum of its weighted inputs and then applies a non-linear (usually logistic) function to the sum. ... The result of the function then becomes the output from that particular middle neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e9fe7",
   "metadata": {},
   "source": [
    "# Explain the learning process of an ANN. Explain, with example, the challenge in assigning synaptic weights for the interconnection between neurons? How can this challenge be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd3504",
   "metadata": {},
   "source": [
    "An artificial neural network's learning rule or learning process is a method, mathematical logic or algorithm which improves the network's performance and/or training time. Usually, this rule is applied repeatedly over the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd8921",
   "metadata": {},
   "source": [
    "# Explain, in details, the backpropagation algorithm. What are the limitations of this algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c75ed6",
   "metadata": {},
   "source": [
    "Essentially, backpropagation is an algorithm used to calculate derivatives quickly. Artificial neural networks use backpropagation as a learning algorithm to compute a gradient descent with respect to weights. ... The algorithm gets its name because the weights are updated backwards, from output towards input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf1c6c",
   "metadata": {},
   "source": [
    "# Describe, in details, the process of adjusting the interconnection weights in a multi-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a0c4d",
   "metadata": {},
   "source": [
    "Recall that in order for a neural networks to learn, weights associated with neuron connections must be updated after forward passes of data through the network. These weights are adjusted to help reconcile the differences between the actual and predicted outcomes for subsequent forward passes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb7fb4",
   "metadata": {},
   "source": [
    "# What are the steps in the backpropagation algorithm? Why a multi-layer neural network is required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5be28b",
   "metadata": {},
   "source": [
    "Calculate the error – How far is your model output from the actual output.\n",
    "Minimum Error – Check whether the error is minimized or not.\n",
    "Update the parameters – If the error is huge then, update the parameters (weights and biases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c960efd",
   "metadata": {},
   "source": [
    "# 8. Write short notes on:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7115d7a",
   "metadata": {},
   "source": [
    "Artificial neuron:-An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human body's biological neural network, have a layered architecture and each network node (connection point) has the capability to process input and forward output to other nodes in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedcad7",
   "metadata": {},
   "source": [
    "Multi-layer perceptron:-A multilayer perceptron (MLP) is a class of feedforward artificial neural network (ANN). ... An MLP consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d1acd",
   "metadata": {},
   "source": [
    "Deep learning:-Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. ... In deep learning, a computer model learns to perform classification tasks directly from images, text, or sound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbe6fd",
   "metadata": {},
   "source": [
    "learning rate:-The amount that the weights are updated during training is referred to as the step size or the “learning rate.” Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d958e6",
   "metadata": {},
   "source": [
    "# 2. Write the difference between:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297cc21",
   "metadata": {},
   "source": [
    "Activation function vs threshold function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9422791",
   "metadata": {},
   "source": [
    "Binary step function is a threshold-based activation function which means after a certain threshold neuron is activated and below the said threshold neuron is deactivated. In the above graph, the threshold is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10881c06",
   "metadata": {},
   "source": [
    "Step function vs sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424a005",
   "metadata": {},
   "source": [
    "The sigmoid function, more commonly used, is asymptotic to 0 and 1 [83] and antisymmetric about (0, ... ... ( 0 n ) are the input weights and g is the non-linear activation function [119], usually a step (threshold) function or sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe810da",
   "metadata": {},
   "source": [
    "Single layer vs multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16cc53",
   "metadata": {},
   "source": [
    "A Multi Layer Perceptron (MLP) contains one or more hidden layers (apart from one input and one output layer). While a single layer perceptron can only learn linear functions, a multi layer perceptron can also learn non - linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eb818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
